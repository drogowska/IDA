{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4a2b909c",
      "metadata": {
        "id": "4a2b909c"
      },
      "source": [
        "### One-class classification\n",
        "\n",
        "To demonstrate how to implement network models in one-class classification, we will use the IMDb (Internet Movies Database) movie review library, which is also available at the following links: https://www.imdb.com/interfaces/ or https://www.kaggle.com/lakshmi25npathi/datasets. In this dataset, we find $50000$ movie reviews that are classified into one of two classes, i.e. positive or negative review. Moreover, this set was divided into a training set ($25000$ reviews) and a test set ($25000$ reviews). In each subset we have exactly half of positive and negative reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e05791",
      "metadata": {
        "id": "e0e05791"
      },
      "source": [
        "#### Prepare input data\n",
        "\n",
        "The IMDb collection is included with the Keras package and has been prepared for direct use, i.e. textual reviews have been converted into vectors of integers, with each number representing a word number (index) key in the dictionary. Additionally, each input vector is assigned a label of $0$ or $1$, which indicates a negative or positive review, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0084ebbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0084ebbf",
        "outputId": "df6ce1d8-62d0-4e3a-a6c6-250c5a37eece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training samples: 25000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# a number of keywords\n",
        "L=100\n",
        "# download training and testing datasets limited to L keywords\n",
        "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=L+4)\n",
        "N=len(train_data)\n",
        "print('The number of training samples:',N)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faefbf6f",
      "metadata": {
        "id": "faefbf6f"
      },
      "source": [
        "The imdb.load_data function accepts an argument specifying the number of keywords (the first $L$ most frequently occurring) to be taken into account (the value $L+4$ was entered because the index $0$ is used to complete the vector, $1$ means the start of the review text , $2$ means a word that does not appear in the dictionary, $3$ is not used). The $N$ variable (**N=len(train_data)**) specifies the number of data vectors in the training set. Below is an example input vector describing a sample review with a maximum of $15$ of keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "28c54b56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28c54b56",
        "outputId": "18f91c3b-e02a-4f0d-9929-13dd5eb48792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplary review:\n",
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 4, 2, 36, 2, 5, 25, 100, 43, 2, 2, 50, 2, 2, 9, 35, 2, 2, 5, 2, 4, 2, 2, 2, 2, 2, 2, 39, 4, 2, 2, 2, 17, 2, 38, 13, 2, 4, 2, 50, 16, 6, 2, 2, 19, 14, 22, 4, 2, 2, 2, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 2, 12, 8, 2, 8, 2, 5, 4, 2, 2, 16, 2, 66, 2, 33, 4, 2, 12, 16, 38, 2, 5, 25, 2, 51, 36, 2, 48, 25, 2, 33, 6, 22, 12, 2, 28, 77, 52, 5, 14, 2, 16, 82, 2, 8, 4, 2, 2, 2, 15, 2, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 7, 4, 2, 2, 13, 2, 88, 4, 2, 15, 2, 98, 32, 2, 56, 26, 2, 6, 2, 2, 18, 4, 2, 22, 21, 2, 2, 26, 2, 5, 2, 30, 2, 18, 51, 36, 28, 2, 92, 25, 2, 4, 2, 65, 16, 38, 2, 88, 12, 16, 2, 5, 16, 2, 2, 103, 32, 15, 16, 2, 19, 2, 32]\n"
          ]
        }
      ],
      "source": [
        "print('Exemplary review:')\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e01d6bf",
      "metadata": {
        "id": "6e01d6bf"
      },
      "source": [
        "This way of representing data is not directly suitable for training a neural network model. First of all, it should be noted that each input vector describing a single review may have a different size. Therefore, a process of preparing input data for the neural network training process is required. Since the number of keywords is strictly defined,\n",
        "then we have at least two possibilities here: (I) for each review we can create a vector of length $L$ elements and mark the occurrence of specific keywords with the values $1$, where the keywords are represented by the indexes of the elements in the vector, (II) similarly to the case of (I ), but this time we can count the occurrences of specific words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "53eafda6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def prepare_data(name,data,labels):\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=L)\n",
        "    x_tfidf = tfidf_vectorizer.fit_transform([\" \".join(map(str, review)) for review in data])\n",
        "\n",
        "    # Normalize the TF-IDF vectors\n",
        "    x_tfidf_normalized = x_tfidf / np.linalg.norm(x_tfidf, axis=1, keepdims=True)\n",
        "\n",
        "    # Save TF-IDF data and labels\n",
        "    np.save(name + '_data.npy', x_tfidf_normalized)\n",
        "    np.save(name + '_labels.npy', labels)\n",
        "    \n",
        "prepare_data('train',train_data,train_labels)\n",
        "prepare_data('test',test_data,test_labels)\n",
        "    # Convert reviews to TF-IDF representation\n",
        "    # tfidf_vectorizer = TfidfVectorizer(max_features=L)\n",
        "    # train_data = tfidf_vectorizer.fit_transform([\" \".join(map(str, review)) for review in train_data])\n",
        "    # # train_labels = tfidf_vectorizer.fit_transform([\" \".join(map(str, review)) for review in train_labels])\n",
        "    # test_data = tfidf_vectorizer.transform([\" \".join(map(str, review)) for review in test_data])\n",
        "    # # test_labels = tfidf_vectorizer.transform([\" \".join(map(str, review)) for review in test_labels])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0f5a7f9e",
      "metadata": {
        "id": "0f5a7f9e"
      },
      "outputs": [],
      "source": [
        "def prepare_data(name,data,labels):\n",
        "    global N,L\n",
        "\n",
        "    x=np.zeros((N,L),float)\n",
        "    y=np.zeros((N,1),float)\n",
        "    for i in range(0,N):\n",
        "        for j in data[i]:\n",
        "            # here we can decide, wether we want to count or indicate the occurences of words\n",
        "            # =1 allows to indicate the occurence of a specific words\n",
        "            # +=1 allows to count the numbers of occurrences\n",
        "            x[i][j-4]=1\n",
        "        # we use normalization in case of counting words\n",
        "        x[i]/=np.linalg.norm(x[i])\n",
        "        y[i]=labels[i]\n",
        "    np.save(name+'_data.npy',x)\n",
        "    np.save(name+'_labels.npy',y)\n",
        "    \n",
        "    return\n",
        "\n",
        "# preparation of input data\n",
        "prepare_data('train',train_data,train_labels)\n",
        "prepare_data('test',test_data,test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85065a69",
      "metadata": {
        "id": "85065a69"
      },
      "source": [
        "Of course, it is possible to recreate individual reviews through a reverse mapping process, i.e. keyword-to-keyword index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "07639f02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07639f02",
        "outputId": "67597196-6496-44f4-9ee0-8332631d3367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "? this film was just ? ? ? ? story ? ? really ? the ? they ? and you could just ? ? there ? ? is an ? ? and ? the ? ? ? ? ? ? from the ? ? ? as ? so i ? the ? there was a ? ? with this film the ? ? ? the film were great it was just ? so much that i ? the film as ? as it was ? for ? and would ? it to ? to ? and the ? ? was ? really ? at the ? it was so ? and you ? what they ? if you ? at a film it ? have been good and this ? was also ? to the ? ? ? that ? the ? of ? and ? they were just ? ? are ? ? out of the ? ? i ? because the ? that ? them all ? up are ? a ? ? for the ? film but ? ? are ? and ? be ? for what they have ? don't you ? the ? story was so ? because it was ? and was ? ? after all that was ? with ? all\n"
          ]
        }
      ],
      "source": [
        "def decode_data(data):\n",
        "\n",
        "    dictionary=imdb.get_word_index()\n",
        "    my_dictionary=dict([(k,v) for (v,k) in dictionary.items()])\n",
        "    s=' '.join([my_dictionary.get(d-3,'?') for d in data])\n",
        "    return s\n",
        "\n",
        "print(decode_data(train_data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17feac14",
      "metadata": {
        "id": "17feac14"
      },
      "source": [
        "The next step is to divide the test set into two parts, i.e. one used for testiung and the other serving as a validation set. In our example, we divide it in half."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a735944f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a735944f",
        "outputId": "01d1bb9f-ad09-44b7-93d9-2116b0f09bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplary vector discribing one review:\n",
            "[0.204 0.204 0.204 0.204 0.204 0.204 0.204 0.    0.    0.204 0.204 0.\n",
            " 0.204 0.    0.    0.    0.    0.    0.    0.204 0.    0.204 0.    0.204\n",
            " 0.204 0.204 0.    0.204 0.204 0.    0.    0.    0.    0.    0.204 0.\n",
            " 0.    0.    0.    0.    0.    0.    0.204 0.    0.    0.    0.    0.\n",
            " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
            " 0.    0.204 0.    0.    0.204 0.    0.    0.    0.    0.    0.    0.\n",
            " 0.204 0.204 0.204 0.   ]\n"
          ]
        }
      ],
      "source": [
        "train_x=np.load('train_data.npy')\n",
        "train_y=np.load('train_labels.npy')\n",
        "test_x=np.load('test_data.npy')\n",
        "test_y=np.load('test_labels.npy')\n",
        "N=len(test_x)\n",
        "N2=N//2\n",
        "(test_x,validate_x)=(test_x[0:N2],test_x[N2:N])\n",
        "(test_y,validate_y)=(test_y[0:N2],test_y[N2:N])\n",
        "print('Exemplary vector discribing one review:')\n",
        "print(np.round(test_x[0],3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba11c34d",
      "metadata": {
        "id": "ba11c34d"
      },
      "source": [
        "#### Construction of a neural network model\n",
        "\n",
        "In the binary classification task under consideration, the input of the neural network is vectors of size $L$-elements ($L$ is the number of the most important keywords), while the output is one value from the range $[0,1]$, which determines the affiliation to one of two classes. A value of $1$ indicates a positive review. In turn, the value $0$ is a negative review.\n",
        "\n",
        "In our example study, we will use a network with one layer and the number of $1$ neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "60bed432",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60bed432",
        "outputId": "4f5c2a58-423c-4220-bf58-e365d1428638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (25000, 32)               3232      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (25000, 1)                33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3265 (12.75 KB)\n",
            "Trainable params: 3265 (12.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# neural network - building the model\n",
        "model=tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Embedding(N, 16))\n",
        "# model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.build(input_shape=(N,L))\n",
        "# model.compile(optimizer='Adam',loss=tf.keras.losses.MeanSquaredError(),metrics=['accuracy'])\n",
        "model.compile(optimizer='Adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea09a897",
      "metadata": {
        "id": "ea09a897"
      },
      "source": [
        "We carry out the training process taking into account the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "be4a7054",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be4a7054",
        "outputId": "cf059c10-63d8-40dc-b786-0a8946ecdcd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 3s 6ms/step - loss: 0.6423 - accuracy: 0.6531 - val_loss: 0.5964 - val_accuracy: 0.6939\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5794 - accuracy: 0.7006 - val_loss: 0.5661 - val_accuracy: 0.7061\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5669 - accuracy: 0.7047 - val_loss: 0.5623 - val_accuracy: 0.7085\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5639 - accuracy: 0.7083 - val_loss: 0.5587 - val_accuracy: 0.7129\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5632 - accuracy: 0.7059 - val_loss: 0.5583 - val_accuracy: 0.7130\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5624 - accuracy: 0.7064 - val_loss: 0.5579 - val_accuracy: 0.7128\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5618 - accuracy: 0.7076 - val_loss: 0.5589 - val_accuracy: 0.7122\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5619 - accuracy: 0.7068 - val_loss: 0.5580 - val_accuracy: 0.7145\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5605 - accuracy: 0.7101 - val_loss: 0.5573 - val_accuracy: 0.7126\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5603 - accuracy: 0.7085 - val_loss: 0.5582 - val_accuracy: 0.7134\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5593 - accuracy: 0.7087 - val_loss: 0.5575 - val_accuracy: 0.7126\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5583 - accuracy: 0.7099 - val_loss: 0.5566 - val_accuracy: 0.7150\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5571 - accuracy: 0.7109 - val_loss: 0.5582 - val_accuracy: 0.7093\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5567 - accuracy: 0.7107 - val_loss: 0.5570 - val_accuracy: 0.7137\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.7116 - val_loss: 0.5565 - val_accuracy: 0.7141\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5547 - accuracy: 0.7110 - val_loss: 0.5590 - val_accuracy: 0.7066\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5534 - accuracy: 0.7138 - val_loss: 0.5561 - val_accuracy: 0.7130\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5524 - accuracy: 0.7150 - val_loss: 0.5560 - val_accuracy: 0.7130\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5515 - accuracy: 0.7162 - val_loss: 0.5564 - val_accuracy: 0.7139\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5511 - accuracy: 0.7149 - val_loss: 0.5570 - val_accuracy: 0.7110\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5498 - accuracy: 0.7165 - val_loss: 0.5577 - val_accuracy: 0.7133\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5494 - accuracy: 0.7177 - val_loss: 0.5557 - val_accuracy: 0.7155\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5481 - accuracy: 0.7200 - val_loss: 0.5556 - val_accuracy: 0.7150\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.5474 - accuracy: 0.7192 - val_loss: 0.5563 - val_accuracy: 0.7145\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5463 - accuracy: 0.7199 - val_loss: 0.5557 - val_accuracy: 0.7132\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5459 - accuracy: 0.7204 - val_loss: 0.5562 - val_accuracy: 0.7128\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5446 - accuracy: 0.7217 - val_loss: 0.5554 - val_accuracy: 0.7152\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5437 - accuracy: 0.7230 - val_loss: 0.5613 - val_accuracy: 0.7099\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5433 - accuracy: 0.7226 - val_loss: 0.5559 - val_accuracy: 0.7140\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5416 - accuracy: 0.7237 - val_loss: 0.5560 - val_accuracy: 0.7145\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5412 - accuracy: 0.7260 - val_loss: 0.5571 - val_accuracy: 0.7116\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5403 - accuracy: 0.7260 - val_loss: 0.5582 - val_accuracy: 0.7101\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5405 - accuracy: 0.7256 - val_loss: 0.5569 - val_accuracy: 0.7138\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5387 - accuracy: 0.7266 - val_loss: 0.5562 - val_accuracy: 0.7137\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5387 - accuracy: 0.7274 - val_loss: 0.5563 - val_accuracy: 0.7128\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5376 - accuracy: 0.7274 - val_loss: 0.5620 - val_accuracy: 0.7077\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5366 - accuracy: 0.7286 - val_loss: 0.5578 - val_accuracy: 0.7122\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5359 - accuracy: 0.7284 - val_loss: 0.5566 - val_accuracy: 0.7124\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5349 - accuracy: 0.7291 - val_loss: 0.5568 - val_accuracy: 0.7131\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.7303 - val_loss: 0.5574 - val_accuracy: 0.7120\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5336 - accuracy: 0.7306 - val_loss: 0.5570 - val_accuracy: 0.7112\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5328 - accuracy: 0.7314 - val_loss: 0.5570 - val_accuracy: 0.7125\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5321 - accuracy: 0.7320 - val_loss: 0.5606 - val_accuracy: 0.7094\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5318 - accuracy: 0.7320 - val_loss: 0.5576 - val_accuracy: 0.7105\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5306 - accuracy: 0.7326 - val_loss: 0.5577 - val_accuracy: 0.7114\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5298 - accuracy: 0.7325 - val_loss: 0.5577 - val_accuracy: 0.7114\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5291 - accuracy: 0.7335 - val_loss: 0.5583 - val_accuracy: 0.7107\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5290 - accuracy: 0.7356 - val_loss: 0.5624 - val_accuracy: 0.7085\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5281 - accuracy: 0.7337 - val_loss: 0.5592 - val_accuracy: 0.7113\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5276 - accuracy: 0.7367 - val_loss: 0.5586 - val_accuracy: 0.7123\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5265 - accuracy: 0.7364 - val_loss: 0.5599 - val_accuracy: 0.7114\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5261 - accuracy: 0.7372 - val_loss: 0.5588 - val_accuracy: 0.7111\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5254 - accuracy: 0.7350 - val_loss: 0.5606 - val_accuracy: 0.7112\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5248 - accuracy: 0.7369 - val_loss: 0.5611 - val_accuracy: 0.7082\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7384 - val_loss: 0.5604 - val_accuracy: 0.7107\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5233 - accuracy: 0.7383 - val_loss: 0.5597 - val_accuracy: 0.7096\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5224 - accuracy: 0.7394 - val_loss: 0.5608 - val_accuracy: 0.7091\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7382 - val_loss: 0.5618 - val_accuracy: 0.7090\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5212 - accuracy: 0.7396 - val_loss: 0.5613 - val_accuracy: 0.7102\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5207 - accuracy: 0.7394 - val_loss: 0.5612 - val_accuracy: 0.7086\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7403 - val_loss: 0.5617 - val_accuracy: 0.7098\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7409 - val_loss: 0.5608 - val_accuracy: 0.7082\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5188 - accuracy: 0.7433 - val_loss: 0.5619 - val_accuracy: 0.7087\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5185 - accuracy: 0.7419 - val_loss: 0.5620 - val_accuracy: 0.7104\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5172 - accuracy: 0.7418 - val_loss: 0.5619 - val_accuracy: 0.7094\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5173 - accuracy: 0.7428 - val_loss: 0.5623 - val_accuracy: 0.7090\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.7426 - val_loss: 0.5639 - val_accuracy: 0.7054\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5156 - accuracy: 0.7444 - val_loss: 0.5628 - val_accuracy: 0.7079\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5153 - accuracy: 0.7456 - val_loss: 0.5637 - val_accuracy: 0.7082\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5151 - accuracy: 0.7453 - val_loss: 0.5633 - val_accuracy: 0.7084\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5147 - accuracy: 0.7448 - val_loss: 0.5654 - val_accuracy: 0.7050\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.7437 - val_loss: 0.5643 - val_accuracy: 0.7089\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5125 - accuracy: 0.7466 - val_loss: 0.5652 - val_accuracy: 0.7074\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5127 - accuracy: 0.7473 - val_loss: 0.5650 - val_accuracy: 0.7046\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5122 - accuracy: 0.7484 - val_loss: 0.5650 - val_accuracy: 0.7070\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5115 - accuracy: 0.7459 - val_loss: 0.5668 - val_accuracy: 0.7038\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5112 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7030\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7490 - val_loss: 0.5655 - val_accuracy: 0.7066\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5100 - accuracy: 0.7472 - val_loss: 0.5670 - val_accuracy: 0.7070\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5102 - accuracy: 0.7484 - val_loss: 0.5678 - val_accuracy: 0.7039\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5091 - accuracy: 0.7490 - val_loss: 0.5669 - val_accuracy: 0.7050\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5088 - accuracy: 0.7489 - val_loss: 0.5674 - val_accuracy: 0.7056\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5087 - accuracy: 0.7467 - val_loss: 0.5670 - val_accuracy: 0.7073\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5083 - accuracy: 0.7494 - val_loss: 0.5682 - val_accuracy: 0.7042\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5075 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7050\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5068 - accuracy: 0.7503 - val_loss: 0.5683 - val_accuracy: 0.7044\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5057 - accuracy: 0.7511 - val_loss: 0.5682 - val_accuracy: 0.7060\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5056 - accuracy: 0.7521 - val_loss: 0.5774 - val_accuracy: 0.6973\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5068 - accuracy: 0.7506 - val_loss: 0.5710 - val_accuracy: 0.7022\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5052 - accuracy: 0.7507 - val_loss: 0.5802 - val_accuracy: 0.6938\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5046 - accuracy: 0.7507 - val_loss: 0.5703 - val_accuracy: 0.7046\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5039 - accuracy: 0.7533 - val_loss: 0.5710 - val_accuracy: 0.7038\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5034 - accuracy: 0.7513 - val_loss: 0.5705 - val_accuracy: 0.7050\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5029 - accuracy: 0.7534 - val_loss: 0.5717 - val_accuracy: 0.7041\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5027 - accuracy: 0.7536 - val_loss: 0.5712 - val_accuracy: 0.7058\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5020 - accuracy: 0.7538 - val_loss: 0.5718 - val_accuracy: 0.7054\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5023 - accuracy: 0.7528 - val_loss: 0.5722 - val_accuracy: 0.7046\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.7558 - val_loss: 0.5761 - val_accuracy: 0.7049\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.7558 - val_loss: 0.5729 - val_accuracy: 0.7052\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5010 - accuracy: 0.7556 - val_loss: 0.5754 - val_accuracy: 0.7042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Toshiba\\AppData\\Local\\Temp\\ipykernel_5500\\814429872.py:3: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  tf.keras.models.save_model(model,'model_1.h5')\n"
          ]
        }
      ],
      "source": [
        "# siec neuronowa - trenowanie modelu\n",
        "history=model.fit(train_x,train_y,epochs=100,batch_size=100,validation_data=(validate_x,validate_y))\n",
        "tf.keras.models.save_model(model,'model_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f124272",
      "metadata": {
        "id": "4f124272"
      },
      "source": [
        "After training, we save our model (weights and network structure) to a file with the \".h5\" extension using the save_model() function. Such a model can then be repeatedly loaded into memory and used in a classification task without the need for retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a7f48203",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "a7f48203",
        "outputId": "08196121-876e-4155-ecca-b40e45a47492"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABR60lEQVR4nO3dd3hUVfrA8e+Zksxk0nsjhRJaIARCBwGRoq4ouq64upafZVdd3aar7rq2XVddXbvril3XVRBXxYpYQSnSSyC0EEjvmSQzk0w7vz/uMCaQQIBAYHI+z5MH5tZzM/DOmfee814hpURRFEUJXLqeboCiKIpyYqlAryiKEuBUoFcURQlwKtAriqIEOBXoFUVRApyhpxtwsNjYWJmRkdHTzVAURTmtrFu3rkZKGdfRulMu0GdkZLB27dqeboaiKMppRQixr7N1KnWjKIoS4FSgVxRFCXAq0CuKogQ4FegVRVECnAr0iqIoAU4FekVRlACnAr2iKEqAO+XG0SuKogQsKSH/f1C9A4QOhB4MQWAM0X7CEqH/9G4/rQr0iqIoJ0OLFT78DeS/1/k2qaNVoFcURekRNbtg+2IYPAdiB/y4vGIL/DAfmqvB2QytTdDaqAX11maI6Q+ZkyFxOCx7BBr2w1n3woTfaPtLD7hbweUAlw0QJ6T5XQr0QojZwJOAHnhRSvnQQesfB6b5XoYA8VLKSN86D7DFt26/lHJON7RbURTl6LlaoOQHKPwWPK2QcykkDO18e68HVv0LvvobuFu0P4ddDCMug/Wvw9ZFEBQGURkQHAqWOC24m8K1VEzlVlj3GrgdEJ4CV38CaePanEAHeqO2Lx2WqekWRwz0Qgg98CwwAygB1gghFksptx3YRkr5uzbb3wzktjmEQ0o5ottarCiK0lXNVbB3GZRtgLKNULpWC9gH8uMrnoaUUZB1tta7dtrA4/St10HxaihZAwPPgWl/hk1vwZqXYPMCLZBP/gNMuBnMUZ23we3UAn5MPzBFnLRLb6srPfoxwG4pZSGAEOJt4HxgWyfbXwrc0z3NUxQlYHnc0LAPovuC6CRlYa+D+r3g9YLeAAYTxGaBTv/jNl4vbH0XdDoYMBOCw7QUyvdPaYHc7QB9MCRmw6irIHMKZEzUzr95Aax/Db7+m3Ysg0nbVnq1wG+KgAtf0HrxQkDiAzDxN7BrKfQ/C8ISjnydhiBIGXncv67j0ZVAnwIUt3ldAoztaEMhRDqQCXzVZrFJCLEWcAMPSSnf72C/64HrAdLS0rrUcEVRTkGOBtj7rRYIpRem3gmRfdpv43HDlnfg24e1IJ4wDMbfCEMvhKp82Pm5dozqHeCoO/QcCdkw6wHoOxXqCuH9m2D/Cm2dPhj6TtF677Yq7ZgTbobEYVqK5GDjb4RxN4DLrgX5th8gnQmNh9zLjvIX07O6+2bsPGCRlNLTZlm6lLJUCNEX+EoIsUVKuaftTlLK+cB8gLy8PNnNbVIU5USp2Q27lkBlvnZjsjJf6wkHR4DXBfnvw7Q/wZjrtPV7vtbSH3V7tBuU0++BzQvh/Rtg8c3gdQNC6wEPmQMxA7Qev94IHhc0V8J3j8Hr50PGZChdrwXn85/Vttu2GHZ8AnED4dK3IDXvyNcgBARZTvRvqkcJKQ8fV4UQ44F7pZSzfK/vBJBSPtjBthuAm6SUKzo51qvAR1LKRZ2dLy8vT6p69IpyknlcsO972POV1hM3R2k/YUkQ0UfrlbfNL0upjTb5/C/aTc3QBO2mZvJILaWROhqayuDjW7UPAp1RC/wILSc+6Xcw6FwtyEqpnXfnEi3A9z8LLLGdt9XVAqv/Dcv/qQXyOU9DROoJ/xWd6oQQ66SUHX6ydSXQG4CdwHSgFFgD/FxKmX/QdoOAz4BM6TuoECIKsEspW4UQscBK4Py2N3IPpgK9opxExWvgh+e1dEmrVQvIOoOW1z5YVKYWhPtO0Uac7Ppcy4n/5PHOA62UsP1DKFqujTbJnAqWmO5pu8fVcTqmlzpcoD9i6kZK6RZC/BpYgja88mUpZb4Q4n5grZRysW/TecDbsv0nx2DgeSGEF63cwkOHC/KKohwljwtWPQdF38GAGVpO+uBA6vVCdQGUb9LSHMYQLSe95iUoXqX11Iecp40s6TtVS2O4WsBRD41lYN0P9ftg/0rY+CaseUHLhZ/9iJaS6exGKmjrhszRfrqbCvJddsQe/cmmevSK0kVF32mpkertWoqlqVzrjfcZp43j1ht/HDfuqD90/8g0GHcT5F7uG8fdBe5WKP4BIlK0nLhyyjiuHr2iKKcAawnsX6X1ymv3QO0uqNmpBetL34as2dqN0C3vaGmSBquWExd6LReePhFS8rSx4S67dtMzcbg2ZPFoGIK1mZ7KaUUFekU50Q58az5w47FiM+z+QpudaYnVUib9p2tjxre8o40Jb6oEc6R2Q9RWA40l2jH0QVpPOjZLm5055noICtHWJWZrP4pyEBXoFeVYSanNojQEH7rO69VGsWz8r1Yjxdms3egUOm2UCmjjwau2aYFd6LTRLgjImAT9ztTGpDvqIToT+twMaWO1MedH2wtXej31L0ZRjmTXUm2USXA4hERrveqKLVC+UZtiP+Ln2ljxiFStONX6N2DlM9qsz6AwGHKBltP2OLWUSfwQLZCHJWofCKXrtCGIpkjIvhDCk3v4gpVAowK9ooBWffD7J7TgnHeNNvrE69Gmxn/3OIQmar1ue4020iVuoBasjWbY8B+tVz50rpaSsVVDn7Fw5l+0/PiB1EpHdDroM1r7UZQTRAV6pXdrrtbGka/8lzZ23ByljftOytGmxBev1uqjzH5IC+pSar3ytkP7Jv4Wvn4ANr2t5don/R7SJxx+2KGinERqeKUSWJz2NtUJddBUAbW7tZ8DeXK9QRsXvm8F1OzQ9hs6V6tOGJmmBewVT0FjuTYZKOeSrp3b6+larRRFOQHU8Eol8Hjc2vDC8k1avrx6O1Tv/HF0ypEEh2vplZx5kDWrfU3yUVdC7i+0YYhdHV8OKsgrpywV6JVTX+0ebbp94bfQWKrlwG3VvgJYgMEMcVlauiQuS7sBeqDMbEis9kSgmP7aDFCvW8uxG4IPH5h1uqML8opyClOBXulZUmo989L1Wt7bEKylQGp2aUMPyzdplQ5BC9bR/SBpOFjiIW6QlkuP6d/1IYd6o5o6r/Q6KtArJ56UWt3x0vVQX/Rj/ry5EnZ+ptUU70hkupZSGftLrXhWdOZJbbaiBAoV6JVjc6C0bO0ebXSJTq/lvcMStborjnptwtC+FdrIlY5qreiDtKf9jL9Jqy2O0G6kIrWeu0qdKEq3UIFeOXrVO+DT26Hw6yNvG5sFg36i1Q1PGaWlWUDLoeuM2mPWFEU5oVSgVzrW2qSVoj0QiF0OKPoeCj7UJggFWeDsf2hlcZFaXr21Uaug2FiuTRJKG689dk1RlB6lAr3yI3udVpdl67taCVwptUAdGq/dHHW3aJOIci/XZn0e8hSgJG3GqKIopxQV6HszKcFaDDs+g4KPfMHdo+XHJ/1Oy6FbS7RJRxmTtVmf6RO1GaKKopw2VKAPRF4vbFmojT2PzdLqjkf20YYxVuZD1XZt9Ev9PnDZtH1iB8LEW7QZoonD1fR9RQkgKtAHmqLvYcmftMqKljjY+j+gTZkLncE3Hr2vVrgrKhP6TdMmFSmKEpBUoA8E1Tu11EvBx1C6FsJT4MIXIPun2jT+ynwtRRM7QJtk1FH9dEVRApYK9Kc6Rz3s/Bx2fKKlUwbP0WqzSK/2NKK1r2hPLAI8MTm0Zt6Ecco1GFLTEQem8aeNBcYe8VRSSoRK2ShKwFGB/ghaduzAubeI0DOnoQs6/Jhv6fVi/WAx1g8+IOneewjKyOhwO29LC576egwJCVowPljdXm3G6I5PtUlHXjfSkojAC/nvabVddHqtGmNCNnLGgzTsFFS/8B88de/Bg++BXo8xIQFjehpB6ekE9+1H6NQpBKWlHdoep5O6l1+h7pVXSLjrLiLO+0n79XY7zv37cZWV4aqowDJmDMH9+3f5d6goSs/qdWWK3fX1OPfuRbrcSLcLodejM5kQZjOGmBj0MTEIIXDX11P9xJM0LFwIUqKPiyX6iisInz0b5779tO7Ygbu6mqC+mZgGDUK63VQ+/DAtmzaDEJiys8n475sIo1ZXxVVWRumtt9G6Zw9eqxWA2Jt/TdxNN/3YuKoCXG/eQGtBvvY6og+t+gHYqww48vdgTE0h+ZZLCG5arT34ecTlNO9zUvXww7Tu2oU5bxTRv7gCj7VBC8olpVqA3rcPj++cwYMGEXbmNIxpaRjj4/Ha7VQ9+k+cRUXoo6PxOhxkLnqH4H79AHBs2cr+a6/1txlABAUR/8c/EnXZzw/5BuBtaaHsjjuxLV+OMJvRmc0YYmMxDx+OOXcEIWPGYIiOPuL75GlqonXHDlylpZiGDScoM0N921CUwzhcmeJeFehbd++m6LLL2wWtg+kiIgju25fWwkK8zc1EXfZzQidOpO6117GtWNFuWxEUhHQ6/a/1cbHE/+EP6EwmSn/7O2JvvJG4W27G09BA0WWX466sJGLOHAyx0diWf4WjoJD+Sz7DEBsHq5/DtfivFH4UidfVPqAZ09IIyR1B8/Lv8NrtJPz5T4SMHEnlP/6B7dtlGPv0If62WwmbMaPTYOgsKaXpi6U0fb4Ux4YNPz6wGjCmp5F4118Izspi79y5GGKiyViwAOe+fey76mr0oaHE3/oHjKmp6EJDqXzoIWzfLiN02jSS/no/hlhtPL2n2UbJjTdiX7OGiAvnIvQGvC0OXCWltGzdinQ60UVEkPnOwnbfLFp27KT2+efxNNTjaWzCXVeLu6y8/e8gNRXLpImE5OZiGjqUoPR0HJs30/T5UmyrVxM2cwaxv/pVx9+Q0D6AvE1NYDAgjEZ0ISGdbnuAu64O++rV2FauwlVSjGnYcELy8jCPyEEXGqo+eJRTigr0gKuigqJ5lyI9bpLuux+dxYIwGsDjwetw4LU7cFdV0Vq4B+fuPegiIoj/7W8IHvDjaBTH1nwcG9cT3D+L4IFZ6CMicJWW0lJQgKeunvBzz0UfagGvl7Lf3oD1i+WkXTGQ6i9LaCm30+f6MVgsZVC2gdZ6N4WfxhM1wEHiGcHQXEnJpsE0FzpIffppdGFhABiTkzEmJGjXUFVF2e23Y1+5CgBdaCixN9xA1C8uP2JaqS2v3Y67uhp3VRWe5mYsEyagC9Zu0DZ/9z3F111H6NSpODZuRAQHk/6fNwhKTfXvL6Wk/vXXqXz0nwCEnXkmEXPOo2b+fFq25pP80EOHpH+k04lj82aKb/o1xqQkMt5+C53JhKu0lL3z5iGdLoL79kUXFoo+MpLgfv0xDRqIITERx/r1NC//DvuqVXjtdu2Aej14PAijkaAB/Wndtp3QKVNI/sfD6CMi8Doc2Neswf7DD9jXrsOxdSu43f72iOBggvr2JbhvX0LGjCHywrn+b1+e5mYq//YA1vff9/+ejamptO7aBR6Ptr/RiC4sDJ3FAh4P0uUCo4G4m24i4sIL/R8CnmYb1ncXYYiLwzJhAvrIyCO/P04nAq0jcbQ8zc20FhQQPGgQ+lBVK6g36fWB3mO1su/yy3GVlZP+nzcwDR589Adx2uGDG6HgE+0BzqOv1Wq3HOjVOeph95fa2PXdX+JpqGXvZ3G47NptkJTpHsJTW7R66WnjICWP8n8tpOGbTfT7zXBadQMpeXQBcb/7HbG/vL7TZkivl7rXX8ddUUnM9dd1KQ1ytKqefJLa5/6NIS6O9Dde7/ReQ2thIQ0LFmD9YDGehgaE0UjKE48TNn16p8du/vZbin91AxEXXEDC7X+k6OeX4a6pIePN/7T7UO2I9HhwFhbiyM+nddcuTIOHEDp1CjqLhfq33qLy7w9iTE4mKC0N+5o1yNZWMBoxZ2cTkpeHISkR3G6ky427uprWwj207t6Nu6ycoL59if/jbejDIyj74x9xlZX5UnWzMGVnIwwGvDYb9o0badm2DW9jI56mJrw2O0KvRxgNtO7eg2PDBsLnnEfSPfdgW7mSir/+DXdlpXYBOh3mYcMIHjwIY3IKxuRk9JGR6MwmRFAwLQXbaf7qa2wrVyKCgoj4yblEXHgRxoR4mr/7Htvy5XidrUT85LxD7hm1FhZS/+Z/sb73nvZhqNNhGjwYc24uxpQUDPFxBKWmYho+/Li/iXhbWxFCHNMHkXLi9OpA37pnD2V33ElrQQF95j+PpXUZmCO1B0B3VsPc7dSm+5vCtdeNZfDWpVpt9EHnQuE32o3QyHRt9EtLI7T60kHmaOh/FvQ7E3tDJMW33k38H35P1KWXHnIaV2Ule2bOInTKFBxbtqAPDSXzf+/6e5Y9Rbrd1L3xH8KmTe00yLfldTpp/vZbjPHxmHNyjrh99VNPU/Ovf2FMTsZdXU2fl17EMmbMcbfbvn4DZXfegdAbCJ08CcukyYTkjUJn7nwmr5SS5q+/oeof/8BZVARoaaLkf/yDkJG5R3V+6fFQ8+9/U/PMs+jCw/FarQQPHEjiPfcgdILm5d9h+/57nEVFeBoaOjyGMTmZ0GnT8FitNH3+efvUYGwsQq/HXVmJPjIS86hRuKurcZWV4ampQRiNhJ9zDqHTz6S1YAf2tWtxbNmCdDj8x4i8dB6Jf/mLP20lvV6av/4a5/5iPPX1eOrr8dpseB0OZGsrEefPIeL88/37O0tK2X/11XgaGgifPZuI8+dgHjnyiGkw5cTrlYHea7NR89xz1L76GrqQEJLvv5cw65vag58BEobBeU9oVRU9bu0RdPtWws5PtZ65s1mbTJQ8Avav0op8XfQiDDxb+/vmBdoTj4JCtQ8ES6xWcjdlVLsnF0mPB6Hv/ElGVY8+Su2LLwGQ/tZ/Cck9uuByOpIeD8XX/xLb99+T8vhjhJ99dk83CelyUb9gIa7iYmJv/vVxpT1sq1ZT9cgjhJ89m+grr+zwg9trs+EqL8fT2IRsceB1ODCmphKclfVj2sdqpfHTT/E0NRE6cSLBgwaBlNhWrKDh3f/RunMnxsQEDMnJBPfrT8Sc8zDExLS/LinxNjXhrqqiYdG71L36KuHnnEPyQw/iLCmh/K6/4Fi/XtvYYEAfGYneYkGYzUiHA+e+fcRcew1xv/89rv372Xf1/+G12wmdPJmmr75C2u2Yhgwh+dFHCe6rPS9Aer00vLMI5/59xN18MzqTqcPfk9dup3HJ51oKsb4e6fUQc/XVGJOSDvv79drtWBd/SOPHHxMybqx2b+Yw/8d6i14X6KXLReH5F+AsLCRi7lzib74Ow+c3Q9FymPUgRKRoZXabKiCij/Z4OqnlXglNhIGzISIVyjdD2UattstPX4bE7OO/wIN4rFYKz5tD+NmzSbjzzm4//qnK29KCc99+TAOzeropvUrNCy9Q/c/HCB4yGOeu3YiQEBJuv52ws6ajCwtrl9aRbjcVDzxAw1tvEzplCi3btiHdbtJefgnT4MF4bTYaP/uMqkcexdvaSuJdd2HKzqbinntwbNwIgGn4cFKfeRpjfPsqpp6GBop/+SscmzYBIMxmcLvRhYaS/MgjhE6a6N/WVV5Oa2Ehzn37aN25k8aPP8Hb1IQxORlXWRmWCeNJfvRRfxrTY7WCXu//sJZuN83ffEPDO4swJCeRdM89x/U7lFLiqatDHx3t/31JrxfbipU0frgYAH1UNProaIL798ecOwJDVFS7/b2Njbjr6vDUN2CIjsKYnn7cKbVeF+ibv/ue4muvJemhB4mcNQVem6M9lu6Cf8Pwi7WNWpvgu8e1ei9R6RCVAQnZkDRCe17oSeR1Oo/qZqqiHI/6hQupuO9+wmbOIPHPf/aPmuqIlJL6N96g8qGH0UdHk/7Ky4fcS3FVVlJ22x+x//ADCIE+MpKEO25HmM2U3XEn+rAwUp960n9/wFVVRfE11+IsKiL5Hw8TOnUqOrOZ1r17Kb3lN7Tu3k301VcjnU6aly/DtW+//1zCbCZs2jSiLr8cc+4IrP/7HxX3/1VLZeXm0rJ1K64S7QHxhvh4gvr1xbmnEHdVFcJkQra0kPnB+5gGHrnKasuOnVQ99k+CMzIxZWdjSIjHtnw5TZ8vxblvH/qoKELyRhHUrx9NSz7HuXevds8lJAR3fX27lJkxPQ1dUDDu+notbddmYACAISkJy7hxhE6eRPg553TlbTzEcQd6IcRs4ElAD7wopXzooPWPA9N8L0OAeCllpG/dlcBdvnV/k1K+drhzdUegL//L3TR+/DEDvlmCbsEl2szRef+FATOO67iKEii8dju6kJAub+/Ymo8hNgZjYmKH66XHQ92rr+IqKyf21zf5e7AtBQUU33gj7rJy9LGxmIcOpXX3bjz19aQ++wyW8eMPaVfFffdh/WAxwmQiZOwYQidOwjR4EMa0dAzxcYf0fFu2b6fsjjvx2u2Yhg7FNHQIAM7de2gtLMQQHU3kzy7GnJvL7rNmED5jBskPtwthHSq7/Q6sn3yC0Om0G/sAej2WsWMJGTcOZ2Eh9rVrcZWUYBo+nOjLLyNs9mx/p81rs9GybZt2A3/zFqT0YvD19A3RUeijtB9XaSm2lauwr1pF8IABpP/njS6/L20dV6AXQuiBncAMoARYA1wqpdzWyfY3A7lSyv8TQkQDa4E8tMpa64BRUsoOniunOd5AL91udp0xBcuY0aTk7IL9K+GSN7SbqIqinHTu+noaP/qYlvx8WvLz8TpbSXnkEczDh3e4vZQS1/79GBIT/cN+u0vFA3+n/q236P/FUv+HVs3z82letoz0V172jyTy2mzsnHwGEeeeS+Ldf6F1zx5cZWWEjBx5yBBZT7NNG1Z9nKTXq82YP+g+S1cdLtB3pQTCGGC3lLLQd7C3gfOBDgM9cClwIAk2C1gqpazz7bsUmA281fXmHx372nV46uoIC9uh3Vy96EUV5BWlBxmiooj+xeVd3l4IQVB6+glpS/SVV1L/5pvUvfEGCbfdRuOSz6l+/HEArB9+RORFFwLQ+PlSpN1OxNwLEEYjpkGDMA0a1OExuyPIAwid7piD/JF0JRmdAhS3eV3iW3YIIUQ6kAl8dbT7dpemzz9HmIIJlSu1+urDfnoiT6coymkkKDWF8NmzaFiwEPuGDZTdeSfmnByCBw2i9sUXkb4JcdYPPsCYloY5QEbBdfddx3nAIikPDGHpGiHE9UKItUKItdXV1cd8cun10rR0KaHj8tAZpPbQDUVRlDair/4/vM3N7L/iSnSWEFKeeorY66/DuXcvTV9+iausDPvq1UScPydgylx0JdCXAn3avE71LevIPNqnZbq0r5RyvpQyT0qZFxcX14UmdcyxcSPu6mrCJvgm7ViO/ViKogQm87BsQsaMQQKpTz6JMSGesFmzMKanUTv/BayLF4OU7SaKne66EujXAAOEEJlCiCC0YL744I2EEIOAKGBlm8VLgJlCiCghRBQw07fshGhasgRhNBI6zPfZEtL5sDFFUXqvlCceJ3PhAkJGjgRA6PXEXHMNLVu3UvvCi4Tk5bWr73S6O2Kgl1K6gV+jBejtwEIpZb4Q4n4hxJw2m84D3pZthvH4bsL+Fe3DYg1w/4Ebs91NSknj0qVYJk1CT7O20KICvaIohzJERx9S8yriggswxMXhtdmImHtBzzTsBOnSg0eklJ8Anxy07O6DXt/byb4vAy8fY/u6zFVaitfaSNjMmWDbqy1UgV5RlC7SBQURe9ONVD/zLGGzZvV0c7pVwFQiCkpNZcCK7wk/52yw1WhPYQrqnmFPiqL0DlHz5jFg+bKAK/EcUI8S9E+usNWoG7GKohyTQBlp01bA9OjbsdeA5cRMPFAURTndBGagVz16RVEUv8AN9GpopaIoChCIgV5KlbpRFEVpI/ACvdOmPQZQpW4URVGAQAz0Nl+tHJW6URRFAQIx0NtrtT/VZClFURQgEAO9rUb7UwV6RVEUICADvUrdKIqitBV4gd6uevSKoihtBV6gt9WAMUTVuVEURfEJzECv0jaKoih+gRfo7TUqbaMoitJG4AV6W7UK9IqiKG0EYKCvVbNiFUVR2gisQH+gzk2IqnOjKIpyQGAFemezr86NSt0oiqIcEFBPmPpxVqxK3SiBw+VyUVJSQktLS083RTkFmEwmUlNTMRqNXd4nMAO9Gl6pBJCSkhLCwsLIyMgIyMfcKV0npaS2tpaSkhIyMzO7vF9gpW78s2JVjl4JHC0tLcTExKggryCEICYm5qi/3QVWoFepGyVAqSCvHHAs/xYCLNCrgmaK0t0aGhr417/+dUz7nnPOOTQ0NBx2m7vvvpsvvvjimI5/sIyMDGpqarrlWIEksAK9vRaMFggK6emWKErAOFygd7vdh933k08+ITIy8rDb3H///Zx11lnH2jylCwIr0NvUs2IVpbvdcccd7NmzhxEjRnDbbbfxzTffMHnyZObMmcOQIUMAuOCCCxg1ahRDhw5l/vz5/n0P9LCLiooYPHgw1113HUOHDmXmzJk4HA4ArrrqKhYtWuTf/p577mHkyJEMGzaMgoICAKqrq5kxYwZDhw7l2muvJT09/Yg998cee4zs7Gyys7N54oknALDZbJx77rnk5OSQnZ3NggUL/Nc4ZMgQhg8fzq233tqtv79TQYCNuqlWaRsloN33YT7byhq79ZhDksO557yhna5/6KGH2Lp1Kxs3bgTgm2++Yf369WzdutU/8uPll18mOjoah8PB6NGjueiii4iJad/p2rVrF2+99RYvvPACP/vZz3j33Xe5/PLLDzlfbGws69ev51//+hePPvooL774Ivfddx9nnnkmd955J5999hkvvfTSYa9p3bp1vPLKK6xevRopJWPHjmXKlCkUFhaSnJzMxx9/DIDVaqW2tpb33nuPgoIChBBHTDWdjgKrR2+vUTdiFeUkGDNmTLvhfU899RQ5OTmMGzeO4uJidu3adcg+mZmZjBgxAoBRo0ZRVFTU4bEvvPDCQ7b57rvvmDdvHgCzZ88mKirqsO377rvvmDt3LhaLhdDQUC688EKWL1/OsGHDWLp0KbfffjvLly8nIiKCiIgITCYT11xzDf/73/8ICQm81G+A9ehrICG7p1uhKCfM4XreJ5PF8uPzHr755hu++OILVq5cSUhICFOnTu1w+F9wcLD/73q93p+66Ww7vV5/xHsARysrK4v169fzySefcNdddzF9+nTuvvtufvjhB7788ksWLVrEM888w1dffdWt5+1pgdOjl9KXo1epG0XpTmFhYTQ1NXW63mq1EhUVRUhICAUFBaxatarb2zBx4kQWLlwIwOeff059ff1ht588eTLvv/8+drsdm83Ge++9x+TJkykrKyMkJITLL7+c2267jfXr19Pc3IzVauWcc87h8ccfZ9OmTd3e/p7WpR69EGI28CSgB16UUj7UwTY/A+4FJLBJSvlz33IPsMW32X4p5ZxuaPehnM3gaVU5ekXpZjExMUycOJHs7GzOPvtszj333HbrZ8+ezb///W8GDx7MwIEDGTduXLe34Z577uHSSy/ljTfeYPz48SQmJhIWFtbp9iNHjuSqq65izJgxAFx77bXk5uayZMkSbrvtNnQ6HUajkeeee46mpibOP/98WlpakFLy2GOPdXv7e5qQUh5+AyH0wE5gBlACrAEulVJua7PNAGAhcKaUsl4IES+lrPKta5ZShna1QXl5eXLt2rVHfyX2Ovj4D5B7OfSffvT7K8opavv27QwePLinm9GjWltb0ev1GAwGVq5cyQ033OC/OdwbdfRvQgixTkqZ19H2XenRjwF2SykLfQd7Gzgf2NZmm+uAZ6WU9QAHgvxJFRINF79y0k+rKMqJt3//fn72s5/h9XoJCgrihRde6OkmnVa6EuhTgOI2r0uAsQdtkwUghPgeLb1zr5TyM986kxBiLeAGHpJSvn/wCYQQ1wPXA6SlpR1N+xVF6QUGDBjAhg0beroZp63uGnVjAAYAU4FUYJkQYpiUsgFIl1KWCiH6Al8JIbZIKfe03VlKOR+YD1rqppvapCiKotC1UTelQJ82r1N9y9oqARZLKV1Syr1oOf0BAFLKUt+fhcA3QO5xtllRFEU5Cl0J9GuAAUKITCFEEDAPWHzQNu+j9eYRQsSipXIKhRBRQojgNssn0j63ryiKopxgR0zdSCndQohfA0vQ8u8vSynzhRD3A2ullIt962YKIbYBHuA2KWWtEGIC8LwQwov2ofJQ29E6iqIoyonXpQlTUspPpJRZUsp+UsoHfMvu9gV5pOb3UsohUsphUsq3fctX+F7n+P48fIGK49Dc6ubF5YVsLbWeqFMoSq90OpUpVjoWMDNjXW4vf/t4Oz/srevppihKQFFlig/V3aUZTrSACfRhJi0L1dji6uGWKEpgOZ3KFN9www3k5eUxdOhQ7rnnHv/yNWvWMGHCBHJychgzZgxNTU14PB5uvfVWsrOzGT58OE8//XS7NgOsXbuWqVOnAnDvvffyi1/8gokTJ/KLX/yCoqIiJk+ezMiRIxk5ciQrVqzwn+/hhx9m2LBh5OTk+H9/I0eO9K/ftWtXu9cnWsAUNTPodViC9DQ6Tq9PWkU5Kp/eARVbjrzd0UgcBmcfUtXE73QqU/zAAw8QHR2Nx+Nh+vTpbN68mUGDBnHJJZewYMECRo8eTWNjI2azmfnz51NUVMTGjRsxGAzU1R05G7Bt2za+++47zGYzdrudpUuXYjKZ2LVrF5deeilr167l008/5YMPPmD16tWEhIRQV1dHdHQ0ERERbNy4kREjRvDKK69w9dVXH/F83SVgAj1AuNmoevSKchJ0VKb4vffeA/CXKT440B9LmeL//e9/gFZ2+MDxD1emeOHChcyfPx+32015eTnbtm1DCEFSUhKjR48GIDw8HIAvvviCX/3qVxgMWhiMjo4+4nXPmTMHs9kMgMvl4te//jUbN25Er9ezc+dO/3Gvvvpqf7njA8e99tpreeWVV3jsscdYsGABP/zwwxHP110CKtBHmI00OlSgVwLYYXreJ9OpWKZ47969PProo6xZs4aoqCiuuuqqDttxJAaDAa/XC3DI/m2v+/HHHychIYFNmzbh9XoxmUyHPe5FF13k/2YyatSoQz4IT6SAydEDhJtUj15RutvpUqa4sbERi8VCREQElZWVfPrppwAMHDiQ8vJy1qxZA0BTUxNut5sZM2bw/PPP+z9MDqRuMjIyWLduHQDvvvtup22yWq0kJSWh0+l444038Hg8AMyYMYNXXnkFu93e7rgmk4lZs2Zxww03nNS0DQRaoDcbVI5eUbpZ2zLFt9122yHrZ8+ejdvtZvDgwdxxxx0nrEzx559/TnZ2Nu+8806HZYpzcnLIzc1l0KBB/PznP2fixIkABAUFsWDBAm6++WZycnKYMWMGLS0tXHvttaSlpTF8+HBycnL473//6z/Xb37zG/Ly8tDr9Z226cYbb+S1114jJyeHgoICf29/9uzZzJkzh7y8PEaMGMGjjz7q3+eyyy5Dp9Mxc+bM7v4VHdYRyxSfbMdcphj4/YKNrN5bx/d3nNnNrVKUnqPKFAdOmeJHH30Uq9XKX//61+M6zokoU3zaUDdjFSUwBUKZ4rlz57Jnz54eeUxhYAV6k4HmVjder0SnEz3dHEVRukkglCk+MGqoJwRYjt6IlNDUqvL0iqIoBwRcoAfUEEtFUZQ2AivQm3yBXuXpFUVR/AIr0Jt99W7UEEtFURS/wAr0vh69VaVuFKVHhYaGAlBWVsZPf/rTDreZOnUqRxpK/cQTT/gnHkHXyh53xb333ttufHugC6hAH2FWqRtFOZUkJyf7K1Mei4MDfVfKHiuHCqhA78/Rqx69onSbO+64g2effdb/+kBvuLm5menTp/tLCn/wwQeH7FtUVER2djYADoeDefPmMXjwYObOnduu1k1H5YWfeuopysrKmDZtGtOmTQPalxB+7LHHyM7OJjs7myeeeMJ/vs7KIXdm48aNjBs3juHDhzN37lx/eYWnnnqKIUOGMHz4cObNmwfAt99+y4gRIxgxYgS5ubmHLQ1xKgmocfSh/pr0KkevBKaHf3iYgrqCbj3moOhB3D7m9k7XX3LJJfz2t7/lpptuArQKkUuWLMFkMvHee+8RHh5OTU0N48aNY86cOQjR8RyW5557jpCQELZv387mzZvb1WPvqLzwLbfcwmOPPcbXX39NbGxsu2OtW7eOV155hdWrVyOlZOzYsUyZMoWoqKgul0M+4IorruDpp59mypQp3H333dx333088cQTPPTQQ+zdu5fg4GB/uujRRx/l2WefZeLEiTQ3Nx+xkNmpIqB69HqdIMxkUD16RelGubm5VFVVUVZWxqZNm4iKiqJPnz5IKfnTn/7E8OHDOeussygtLaWysrLT4yxbtswfcIcPH87w4cP96xYuXMjIkSPJzc0lPz+fbdsO/2jp7777jrlz52KxWAgNDeXCCy9k+fLlQNfLIYNWmKyhoYEpU6YAcOWVV7Js2TJ/Gy+77DL+85//+EsZT5w4kd///vc89dRTNDQ0+Jef6k6PVh4FVcFSCWSH63mfSBdffDGLFi2ioqKCSy65BIA333yT6upq1q1bh9FoJCMj45jKAndXeeEDuloO+Ug+/vhjli1bxocffsgDDzzAli1buOOOOzj33HP55JNPmDhxIkuWLGHQoEHH3NaTJaB69OCrd6OGVypKt7rkkkt4++23WbRoERdffDGg9Ybj4+MxGo18/fXX7Nu377DHOOOMM/wVIrdu3crmzZuBzssLQ+clkidPnsz777+P3W7HZrPx3nvvMXny5KO+roiICKKiovzfBt544w2mTJmC1+uluLiYadOm8fDDD2O1WmlubmbPnj0MGzaM22+/ndGjR/sfdXiqC8AevUH16BWlmw0dOpSmpiZSUlJISkoCtJK75513HsOGDSMvL++IPdsDddgHDx7M4MGDGTVqFNC+vHCfPn385YUBrr/+embPnk1ycjJff/21f/nIkSO56qqrGDNmDKA9vSk3N/ewaZrOvPbaa/zqV7/CbrfTt29fXnnlFTweD5dffjlWqxUpJbfccguRkZH85S9/4euvv0an0zF06FDOPvvsoz5fTwioMsUA172+luI6O5/99oxubJWi9BxVplg52NGWKQ681I1JPU5QURSlrYAL9BFmoxpeqSiK0kbABfpws1aT3u3x9nRTFEVRTgmBF+h9s2ObVU16RVEUIBADvb8mvQr0iqIoEIiB3l8GQd2QVRRFgUAM9GZVqlhRetqpXqa4t+lSoBdCzBZC7BBC7BZC3NHJNj8TQmwTQuQLIf7bZvmVQohdvp8ru6vhnVEVLBXl1NHbyxRLKfF6e35gyBEDvRBCDzwLnA0MAS4VQgw5aJsBwJ3ARCnlUOC3vuXRwD3AWGAMcI8QIqo7L+BgESGqJr2idKdALFP84YcfMnbsWHJzcznrrLP8xdiam5u5+uqrGTZsGMOHD+fdd98F4LPPPmPkyJHk5OQwffr0dr+HA7KzsykqKqKoqIiBAwdyxRVXkJ2dTXFxcYfXB7BmzRomTJhATk4OY8aMoampiTPOOIONGzf6t5k0aRKbNm3q4rvVsa6UQBgD7JZSFgIIId4Gzgfalpe7DnhWSlkPIKWs8i2fBSyVUtb59l0KzAbeOq5WH4Y/R69uxioBqOLvf6d1e/fWVwkePIjEP/2p0/WBWKZ40qRJrFq1CiEEL774Iv/4xz/45z//yV//+lciIiLYsmULAPX19VRXV3PdddexbNkyMjMzqaurO+LvdNeuXbz22muMGzeu0+sbNGgQl1xyCQsWLGD06NE0NjZiNpu55pprePXVV3niiSfYuXMnLS0t5OTkHPGch9OV1E0KUNzmdYlvWVtZQJYQ4nshxCohxOyj2BchxPVCiLVCiLXV1dVdb30HLEEGdEL16BWluwRimeKSkhJmzZrFsGHDeOSRR8jPzwfgiy++8H+gAURFRbFq1SrOOOMMMjMzAYiOjj7i7yw9Pd0f5Du7vh07dpCUlMTo0aMBCA8Px2AwcPHFF/PRRx/hcrl4+eWXueqqq454viPprqJmBmAAMBVIBZYJIYZ1dWcp5XxgPmi1bo6nITqdIEyVQVAC1OF63idSoJUpvvnmm/n973/PnDlz+Oabb7j33nuP+jwGg6Fd/r1tmy0Wi//vR3t9ISEhzJgxgw8++ICFCxeybt26o27bwbrSoy8F+rR5nepb1lYJsFhK6ZJS7gV2ogX+ruzbLart1cxaNIvFexYTbjaoMgiK0o0CrUyx1WolJUVLLrz22mv+5TNmzGh3P6K+vp5x48axbNky9u7dC+BP3WRkZLB+/XoA1q9f719/sM6ub+DAgZSXl7NmzRoAmpqacLu1uHXttddyyy23MHr0aKKijv+2ZlcC/RpggBAiUwgRBMwDFh+0zftovXmEELFoqZxCYAkwUwgR5bsJO9O3rNtFmiKpsFewv3E/4SajGl6pKN2oszLFa9euZdiwYbz++utdKlPc3NzM4MGDufvuuzssU/zzn/+8wzLFB27GHtC2TPHYsWP9ZYq76t577+Xiiy9m1KhR7fL/d911F/X19WRnZ5OTk8PXX39NXFwc8+fP58ILLyQnJ8f/jeaiiy6irq6OoUOH8swzz5CVldXhuTq7vqCgIBYsWMDNN99MTk4OM2bM8Pf0R40aRXh4OFdffXWXr+lwulSmWAhxDvAEoAdellI+IIS4H1grpVwstLsv/0S70eoBHpBSvu3b9/+AA983H5BSvnK4cx1PmeJZi2aRm5DLvu0X4PJ4WXTDhGM6jqKcSlSZ4t6nrKyMqVOnUlBQgE53aH/8aMsUdylHL6X8BPjkoGV3t/m7BH7v+zl435eBl7tynuOVEpZCaVMpEWYjhTXNJ+OUiqIo3er111/nz3/+M4899liHQf5YBNTM2NTQVEqaS7QcvRpeqSjKaeiKK66guLjYfy+kOwRUoE8JTaHGUUNIsFcNr1QURfEJqECfGpYKgDDWY3d6cKma9EqAONUe+an0nGP5txBQgT4lVBsu5dFpU6Sb1BBLJQCYTCZqa2tVsFeQUlJbW4vJZDqq/bprwtQp4UCPvoVqwEKjw0W0JahnG6Uoxyk1NZWSkhKOd9a4EhhMJhOpqalHtU9ABfoYUwxmgxm7txrIUGPplYBgNBr90+8V5VgEVOpGCEGyJZlGt1ZvQ92QVRRFCbBAD1r6pq61AlAVLBVFUSAAA31KaArVLeWAVD16RVGOisvjosha1NPN6HYBF+hTw1Kxu20IvV3l6BVFOSrPbHyGuR/Mpby5vKeb0q0CLtAfGGIZE9nMxv0NPdsYRVFOSS6vC7vL3m6Z3WXnnZ3v4JZu3t31bg+17MQIuEB/YIjlsHQ33+6spsXl6eEWKYpyqvnbqr9x/gfn0+T8sQTyh3s+pMnZRGpoKu/teg+398Tc43O4HXi8JzcuBV6gD9UCfUqcA4fLw7Kdauyxoig/qnHUsHjPYipsFTy94WkAvNLLmwVvMjRmKLeNvo0qRxXflnzb7efeXb+bs989m0s+uoSy5jL/ciklH+75kDe3v9nt54QADPQhxhCiTdHoguoJNxlYkt/5o80URel9Fu5YiMfrYWqfqbxd8DZba7ayomwFe617uWzwZZyRegbxIfG8s+Odbj3vzvqdXPP5NQghKGsuY95H81hbsZZ9jfu4bul1/Om7P/Hl/i/xyu4v3RJQE6YOSAlNodxWyvTBCXxZUInb48WgD7jPNEVRjpLT42TBjgVMTp3M3yf9nfPfP5/7V95PZHAkseZYZmfMxqAzcNGAi/j3pn9T0lTiTwcfK6/0sr12O7/64lcE6YJ4adZLSCS3fHUL131+HTqhI0gfxF1j7+LigRejE90fqwIy0KeGprKlZgu/GZrAextK+WFvHRP6xx55R0VRAtqSoiXUtdRx2aDLCAsK4/Yxt3Prt7cCcOOIGzHqjQBcOOBCnt/8PO/uepffjPwNTo+TKnsVcSFxBOu1Z9LWOGpYVrKMtRVrCTGGkGhJJM4cR7Wjmr3WvRRZi6iwV1DnqMMt3SSEJPDyrJdJC08D4L/n/pf7Vt6HXuj5Q94fiA+JP2HXHZCBPiUshaX7ljKxfzTBBh1L8itUoFeUXk5KyX+2/4e+EX0ZnzwegJnpM5mcMpnV5au5OOvH+u+JlkTOSD2Dtwre4ot9X7C/ab8/pRJvjic8OJzdDbsBrfSK0+tsd2M3PiSezPBMJiRPINYcS6w5lrPSziLBkuDfJiwojEenPHoyLj0wA31qaCpu6abJXcsZWXF8vq2Se+cMRXvioaIoPaWsuYyCugKm9ZnWrf8fvdKLy+tCSolEaq89LlxebS6NUWekoL6AbbXbuGvsXf5zCyH4xxn/oMJWQay5fWfwmuxrqLRVkhKawsyMmSRbkqlyVFHaVEptSy1nZ57NlNQpZEVlIYTA7rJT7agm1hyLxWjptmvrDgEZ6FPCtLH0JU0lzBqazNJtlWwusZLTJ7JnG6YovVShtZCXtrzEJ4Wf4JZuZqTP4G8T/0aIMcS/TbW9mm2129hWu42ixiL6RfYjNz6X7NhsbC4b+xv3U9pcislgIs4cR5Qpiq01W/mm+Bu+K/2OZteRHx8aFhTGef3Oa7csNCiU/kH9D9l2RPwIFp63sMvXGGIMId2Y3uXtT6aADPQHhliWNpdy1uAR6HWCx5bu5Omf5xJuMvZw6xSl98ivzeelLS/xxb4vCNYHM2/QPKJMUTy78VmKGot4cNKDbKnZwvu732dT9SYABIL4kHg+2fvJEY6uiTHFMDNjJn3C+vj3N+gMGHQGjDrt/7vL68LtdTMkZki7D5feQpxqDzPIy8uTa9euPa5juL1upiyYQrQpmhdmvsBnGx389ePtpESa+ddlI8lOieim1ipK4NtcvZmXtryEEIKJKROZlDwJIQTrK9ezvmo99S31hAaFYjFaMOlN6IQOndCxoWoDq8pXEWYM45JBl3D54MuJMccAsKJ0Bbctu41GZyMAfSP6cl6/88hLyCMrKosQYwjWVisbqzaSX5tPZHAkaeFppIam0uJpodpeTW1LLX0j+pIdm31CRqqcboQQ66SUeR2uC8RAD7C+cj03fnkjkcGRvDTrJcprzNz81gZqm51cNCqFIUnhDEwMZ1BSmOrlK72G2+tmeclyvir+ir4RfZmQPIGsqCyaXE1sqtrE1tqtGHVG4sxxhAWF8d6u9/im5BuigqMINgRTYatod7wQQwjxIfHYXXaaXc20elrxSi8SSZw5jsuHXM7Psn5GaFDoIW0pbixmyb4ljE0cS3ZstrqHdpx6ZaAH2FqzlV8u/SVmg5kXZ75IuCGZuz/Yyrc7q9s9ZjAjJoShKREMTgyjb1wombEW4sKC8XolLq8kNNhAhFl9GHQnKSU2l63DANBTCuoK2Fm/k/P6nnfSg45XehGIYzqvV3qptlfj9Dpxe914vB50QocQQnv0XEstNY4a9jTs4f3d71Npr8RitGBz2QAtb93sbEZyaCwICwrj6qFXc9ngyzAbzBRaC1lRtgKBYGTCSLKisjDoDs0AH4grKnifPL020APsqNvB9UuvB+C5s55jSMwQpJSUW1vYUdHEtvJGtpZa2VJqpaTe0eEx9DrB5AGxzM1NYfrgBCxB+oD+B+z0OHlm4zOcm3kuA6MHnpBzPLj6Qd7d9S7PTH+GcUnjuu24Lo8Lg85w1O/P1pqtXPv5tdhcNmZnzOa+CfcddS63oaWBosYiipuKqbRXkhCSwICoAWRGZPrHXh/g8XrIr83nh4ofWFu5lg2VG/BIDymhKaSEphBlisKgM6AXemwuG+W2ckqbSxEIRsSPYGT8SMKCwlhZtpLvy76nrqWuS22ckDyBn2X9jCl9plDrqGVl+Uo2VG0gyZJEbnwuw2KHAdoY8dqWWvpF9iM8KPyofg9Kz+jVgR6gyFrEL5f+EqvTypPTnmRs0tgOt7O1utlbY2NvjY06mxODXmDU6SissbF4Yyll1hZAC/xmo54Is5G8jCjG941hfL8Y0qJDAuID4Kn1T/HClhdICU3hnfPeISworFuPv6xkGTd9eRNmgxmA52c8T2587nEfd0PVBm756hayorJ4cPKDXZ6AsqNuB/+35P8ICwrjJ31/wvzN8xkYPZAnpz1Jcmiyf7tWTyury1ezo24HOXE5jIgfgVFnZEPVBl7Nf5Vvir/psFesEzrSwtL8QX+vdS+rylf5x133i+hHXmIeZoOZkqYSSppLaHI24fK68Hg9mAwmkixJJIcm4/Q4WV+1nip7FQCRwZFMSJ5AbnwuZoMZo86ITqcDCR6p9eyjTdHEmmOJC4lTQTuA9fpAD1Blr+KXS3/JvsZ9XDTgIhIsCf6JDPEh8SSEJFDbUsuqslWsKl+FzWVjeNxwRsSNYHjccCKCIllTVMfaffU4nB7qW+vY31jMtn0mapv0AKREmpnQL4aJ/WOZOjCOcLOB3Q27SQtLw2To+Kntm6s389i6x8iNz9Vm5ul6NkWUX5vPZR9fxsiEkayvXM9Z6WfxyBmPHPEDrMpehUFnINoUfdjtah21XLj4QmLNsTxz5jNcv/R6ahw1vDjzRYbGDj3mdn+1/yv+uOyPxJpjqWupw2ww8/dJf2diysQOt/dKL1X2KnbW7+Qv3/8Fo87Ia2e/RkpoCstLlnP7stuxu+2khKaQHp6OQWdgVfkqHO4fv/WZDWYSLYnste4lMjiSi7MuJicuhz5hfUiwJFBhq2BXwy521+9md8NudtXvoripmLiQOCYmT2RC8gRGJ47236DsKiklZbYyGlsbyYrKQq/TH/PvTQkcKtD7WFut3Ln8TtZWrm33H/ZgqaGpRAZHUlBXgFtqufxESyKDogcRGRzJxqqNFDUW+bePMyUQrk/Hbe9DcXk8jc2hBEVsxhK7FpeoJUhnIidmLNP6TGNU0mASQxMx6ow8tf4pFuxYQGhQKE3OJobFDuPhMx72DxPrSLOzmaLGInbV72Jn/U521O/AqDNy5dArGZ80/ri+UTg9Ti756BIaWxt574L3WLhjIU+uf5J7x9/LRVkXtdvW5rKxtmItK8tXsrJsJYXWQgSCYXHDmNZnGuOTxtM/qn+7lIWUklu+voUVpSt46ydvkRWVRYWtgqs+u4r6lnrOSj+LM9POZELyBECrD251WimyFrGnYQ8lzSWEB4WTaEkkPiQevdAjpWRv416e3vA0Q2OG8sz0Z6hvqefWb29ld8Nu+kb0xSM9uDwuvHj9E2qsrVZaPa0AxJpjeXX2q6SH/zgGen/jfj7Y8wH7Gvexr3Efzc5mJiRP4My0MxkaM5RN1ZtYUbaC3Q27mZk+kzn95/i/oRzpd2zUGQPim59yalGBvgN2l51aRy3VjmqqHFVU2aoIMYYwNmmsP9A63A7ya/LZUrOF7XXbKagroKGlgeFxwxmZMJL08HSKrEXsqN/B9trt7YI/gNGVRVPNUHSmcgyh29AZG9utFwguHXQpN+fezIqyFdy78l680sv0tOmYDWaC9EE43A5qHbXUttT6Z+QdYNKbGBA1gCp7FZX2SnLicrRxysFRmA1mnF4nO+p2sL1uO+XN5aSGpdIvsh9JliQqbZXsb9pPtb2azIhMhsUNY0PVBt7Y9gbPTn+WM1LPwCu9XL/0ejZVbeIXQ36BV3pp9bSyrXYbm6s345ZuTHoToxJGMT55PA63g2+Lv2Vr7VYA9EJPZkQmSZYknF4nzc5m8mvz+ePoP/KLIb/wX0dZcxnPbnyWb4q/8Q+360iMKYYmZxNOr/OQdZNSJvHPKf/059Vb3C38e9O/2d+0H4PQxlQf6PkKBGFBYaSHp5MWnsaQmCEqpaGc9lSgP0msrVY2VW9if+N+JqVMIiMig3Krg3JrC1WNDjZVFrC8qIBdtaVIfRNBrcMYGDWUwUlhTOwXS1aqi0fXPcjuht04PU5a3C2YDCZizDHEmGJItCSSEZ5BRkQGfSP6khaWhl6nx+lx8v7u93lxy4uU2w59BFp8SDwpoSmUNJVQ7fixPv+Bin1FjUX+hyzM6TeHByY94N+m2l7NlZ9dSXFTMUadEYPOQGZEJuOTxjM+eTwj4kcccqOxyl7FpupNbK/VPhxrW2oJ1gcTrA9mcMxgfjvytx2Oe3Z5XaytWMvGqo0Y9UYsRguhxlAywjPoG9kXi9GClJL61nqq7dV4pAe90GPUGcmIyFBjqZVeTQX6U0xtcytfFVSxtdTK9vImtpc30tTqJtigY0pWHNMGxTOubwwZMUd3c9flcVFoLcThduBwO9AJHQOiBrTLmzc6G6m0VRIfEk9EsDZxzOlxUlBXwJ6GPczKmHXIaBM1VE5RTn3HHeiFELOBJwE98KKU8qGD1l8FPAKU+hY9I6V80bfOA2zxLd8vpZxzuHP1hkB/MLfHy5qiepbkV7Akv4Jy3+iexHATozOjGZkWyci0KAYmhmEyqhtviqIc6rgCvRBCD+wEZgAlwBrgUinltjbbXAXkSSl/3cH+zVLKLs+K6Y2Bvi0pJYU1NlbuqWVlYS3r99X7Az9AVIiRhHATgxLDOGdYElMGxhFsUMFfUXq7wwX6rhQ1GwPsllIW+g72NnA+sO2weynHRAhBv7hQ+sWFcvk4bRRIudXB+n0NFFY3U9HYQmVjC9/urOb9jWWEmQxM6BdDYriJ+HATGTEWzsiKJUyVdVAUxacrgT4FKG7zugToaMbRRUKIM9B6/7+TUh7YxySEWAu4gYeklO8fvKMQ4nrgeoC0tLSut76XSIowc+7w9kP3XB4vK/bU8uGmMjbsr2fFnlp/WYcgvY6J/WM4a0gCw1IiyEpQKR9F6c26q0zxh8BbUspWIcQvgdeAM33r0qWUpUKIvsBXQogtUso9bXeWUs4H5oOWuummNgU0o167cTslK86/zOH0kF9m5bOtFXy6tYKvd2gjbPQ6Qf+4UMb1jWZ8v1jGZkYTZQnqqaYrinKSdSVHPx64V0o5y/f6TgAp5YOdbK8H6qSUh9QCFkK8CnwkpVzU2fl6e46+u0gpKaq1s728kW1ljWwqaWBtUT0OlweAMJOB5AgzqVFmJg2IZebQRFIijzzhR1GUU9Px3ow1oKVjpqONqlkD/FxKmd9mmyQpZbnv73OB26WU44QQUYDd19OPBVYC57e9kXswFehPHKfby+aSBtbtq6eswUGZtYXC6mb2VGtVDIelRDChXwyjM6IZlR6lev2Kcho5rpuxUkq3EOLXwBK04ZUvSynzhRD3A2ullIuBW4QQc9Dy8HXAVb7dBwPPCyG8gA4tR69u4vaQIIOOvIxo8jLa16PZW2NjSX4FX2yr5OXv9/L8skIAIkOMJISZSIgwMSUrjp+OSlXlmhXlNKQmTCnttLg8bC6xsn5/PaX1DioaW9hfa2dHZRNmo565I1OY1D+WxAgTieHaj06nJlIpSk873uGVSi9iMuoZkxnNmMz2vf6tpVZeX1nEu+tK+O/q/f7lYSYDuWlR5KVHkRhuwu5043B5SY0yMzs7EaNelSVQlJ6mevTKUWludbO/1k5Fo1bDJ7+skfX76tlR2cTB/5SSIkxcPTGDc4cnY/T1+kNNBkKCVP9CUbqbqnWjnHCNLS6aWtyEGPWYjHpWFdYyf1khKwtr222n1wlyUiOY1D+WCf1jyU2LVDN7FaUbqECv9JitpVY2lTT4X5c3tPDd7ho2lzTglRBs0DEyLYoxmdEMTgpncFIYfaJCVN5fUY6SCvTKKcfqcLG6sJbVe+tYVVjLtvJGf+rHEqRnZHoU4/rGMCYzmqHJ4SrdoyhHoAK9csqzO93srGxmR0UjW0sb+WFvHTsqtWeq6gT0jQtlaHI4fWNDSY8JIT0mhKyEMCzB6gNAUUAFeuU0VWdzsm5fPVtLreSXNbKtzOp/QDuAENAvLpTs5HCGJkcwNDmcIcnhRIaoiV5K76MCvRIwWlweiuvs7K2xsa28ka2lVraWNlLR+OMHQGiwgWhLEFGWIIYkhXPmoHgm9o9R6R8loKlArwS8muZWf12fisYW6m1OapqdbCxuoLnVTZBBx4jUSLJTIshO0b4B9IuzYFDj/JUAoSZMKQEvNjSYyQPimDwgrt1yp9vLmqI6viqoYv3+ev77wz5aXF4ATEYdQ5LCSY+xYNQLjHod0ZYgRvSJJDctimhV60cJECrQKwEtyKBjYv9YJvaPBbTHNhbW2NhaamVLqZWtpVbWFNXh9kjcXi/1dhcer/YtNzXKTEaMhT7RIfSNtTC2bzRDkyPQq6GfymlGBXqlVzHodWQlhJGVEMaFI1MPWe9wethc0sCG4ga2lTWyv87O5/kV1NqcgFbyYXRGNGnRIaREmkmJMjMgPpSMWIsq96CcslSgV5Q2zEF6xvaNYWzfmHbLq5paWFVYx8o9Nazf18DqwlpsTo9/vVEv6BsbSr94i//PvPRo+kSHnOxLUJRDqJuxinIMpJQ0trgprrOzq6qJnZXN7KxoorDGxv46uz/90yfazMR+sQxICCM1ykxKpJn+8aHq0Y5Kt1M3YxWlmwkhiDAbiUiJIDul/cPUnG4vhTXNrNpTy/d7avl4SzlNa3587LJBJ8hKCCOnTwRhJiMOpweHy0NmrIU5OcnqW4DS7VSPXlFOMCkl9XYXpfUO9tfZ2VZuZXOJdjO41eXFHKQnSK/zzwXIS49i0oBYUiLNJEeaSY/R7gcIoW4CK51T4+gV5TRQXGdn8aYyFm8s85d/OCDCbGRIUri/8NvgpHCVAlLaUYFeUU4zrW4PFdYWShscFFZrs4DzyxrZUdHonwcAEB8WTEqUmaQIE9GWIKJDgkiMMHPmoHgSI0w9eAXKyaZy9Ipymgk26EmPsZAeY2FCv1j/co9XUlRrY3t5I3uqbJQ22CltcFBQ0USD3UW93emvAjoqPYozB8UTbNDR6tY+HPrHh5KdEkFyhEmlgnoRFegV5TSi1wn6xYXSLy60w/Uer2RvTTOfbqng4y3lPLJkR4fbRVuCGJkWSV5GNKN8j4EMMxmwBBvUfIAApFI3ihLArA4XOgFGvQ6PV7Kjson8UiubSqys31dPYY3tkH2CDDpCgw1YgvXEhQaTHPnjsNCcPpH0iwtVs4NPQSpHryhKh2qaW9lU3ECdzUlzq5umFjc2pxtbq5vmFjdVTa2UNTgoa2jB6dHSPxbfpLLzcpKYMSSRUPVMgFOCytEritKh2NBgpg9OOOJ2Xq+ksKaZTcXaoyG/2FbJVwVVBBu2kB4TQlOLG6vDhV4ntAfDRFvIjLUwICGUrIQwMmMtaoRQD1I9ekVRjprXK1m/v56PNpdT1uAgwmwk3GzE5fGyr9bO/jp7uxnCAGHBBmJCg4gPM9E3zkL/eO1eQ0ashdQos7o3cJxUj15RlG6l0wnyMqLJy4judBun28veGhs7KpvYV2Oj1uakzuakwtrC0m2VvN1mtrBeJ4gPC8btlbQ4Pbi8XnJSIzkjK46J/WNJjjARbjYSbNCp0ULHQPXoFUXpEXU2J3uqm9lXa2dfrY3SBgfBBh0mox4pYU1RHfllje32MeoFJqMes1GPOUhPtCWIxHATCeEm+sVrj5UcnBTeK9NEqkevKMopJ9oSRLQlmtGH+VZQ09zKmr111NicNLW4aGpx43B6aHF5sDs91Npa2VnZxLKd1f5qotoQVAuDEsMZlBTGiNRIRmVEEWw4NPhLKdlV1Uxts5MxmdEBO5pIBXpFUU5ZsaHBnD0s6YjbSSkps7awpcRKfpmV7eWNrNtXz+JNZYD2NLExmTEMSQon2KAjyKCjrMHBNzuqKW1wAJAYbuKiUSlcMCKFzNjAesykSt0oihKwrHYXa4rq+G53Dct3VbO/zo7Lo8W8kCA9k/rHcuageMJMRhatK+bbndV4pZYiSosOoW9cKIMTtdpCg5LCT+mbxsc9jl4IMRt4EtADL0opHzpo/VXAI0Cpb9EzUsoXfeuuBO7yLf+blPK1w51LBXpFUU4kr1fi9Hgx6MQhvfZyq4Plu2rYW2Njb7WNXVVN7K2xcWDwkE5AUoT2ZLE+USH0iTaTGhVCuG9WcUiQnowYC1E98Lzh48rRCyH0wLPADKAEWCOEWCyl3HbQpguklL8+aN9o4B4gD5DAOt++9cdwHYqiKMdNpxOYdB3frE2KMPOzvD7tljmcHnZWNrGjsomSOjsl9Q6K6+18v7uGyqYWOuorx4UFMyA+FCGgwe7C6nAxMCGM83KSOWtIAmajnr01WrE6g04wKDGM9BjLCbtH0JUc/Rhgt5SyEEAI8TZwPnBwoO/ILGCplLLOt+9SYDbw1rE1V1EU5eQyB+nJ6RNJTp/IQ9a1uj2UN7TQ3KrNJm5qcbO3xkZBRRO7q5rQ64Q2IigulDVFdXxZUOUbIkq7KqQAZqOeqQPjeO7yUd1+DV0J9ClAcZvXJcDYDra7SAhxBrAT+J2UsriTfVOOsa2KoiinlGCDnoxYS5e2PTDJ7JMtFUgkQ5MjGJwUhpSwvbyR7eVNhJpOzPiY7jrqh8BbUspWIcQvgdeAM7u6sxDieuB6gLS0tG5qkqIoyqnjcJPMDn4cZbefuwvblAJtk1ap/HjTFQApZa2UstX38kVgVFf39e0/X0qZJ6XMi4uL62rbFUVRlC7oSqBfAwwQQmQKIYKAecDithsIIdoOdJ0DbPf9fQkwUwgRJYSIAmb6limKoignyRFTN1JKtxDi12gBWg+8LKXMF0LcD6yVUi4GbhFCzAHcQB1wlW/fOiHEX9E+LADuP3BjVlEURTk51IQpRVGUAHC4cfSn5hQvRVEUpduoQK8oihLgVKBXFEUJcCrQK4qiBLhT7masEKIa2Hcch4gFarqpOaeL3njN0DuvuzdeM/TO6z7aa06XUnY4EemUC/THSwixtrM7z4GqN14z9M7r7o3XDL3zurvzmlXqRlEUJcCpQK8oihLgAjHQz+/pBvSA3njN0DuvuzdeM/TO6+62aw64HL2iKIrSXiD26BVFUZQ2VKBXFEUJcAET6IUQs4UQO4QQu4UQd/R0e04UIUQfIcTXQohtQoh8IcRvfMujhRBLhRC7fH9G9XRbu5sQQi+E2CCE+Mj3OlMIsdr3ni/wldEOKEKISCHEIiFEgRBiuxBifKC/10KI3/n+bW8VQrwlhDAF4nsthHhZCFElhNjaZlmH763QPOW7/s1CiJFHc66ACPRtHmB+NjAEuFQIMaRnW3XCuIE/SCmHAOOAm3zXegfwpZRyAPCl73Wg+Q0/PusA4GHgcSllf6AeuKZHWnViPQl8JqUcBOSgXX/AvtdCiBTgFiBPSpmNVhp9HoH5Xr+K9gzttjp7b88GBvh+rgeeO5oTBUSgp80DzKWUTuDAA8wDjpSyXEq53vf3JrT/+Clo1/uab7PXgAt6pIEniBAiFTgX7QlmCCEE2uMqF/k2CcRrjgDOAF4CkFI6pZQNBPh7jfacDLMQwgCEAOUE4HstpVyG9vyOtjp7b88HXpeaVUDkQQ98OqxACfS98iHkQogMIBdYDSRIKct9qyqAhJ5q1wnyBPBHwOt7HQM0SCndvteB+J5nAtXAK76U1YtCCAsB/F5LKUuBR4H9aAHeCqwj8N/rAzp7b48rxgVKoO91hBChwLvAb6WUjW3XSW3MbMCMmxVC/ASoklKu6+m2nGQGYCTwnJQyF7BxUJomAN/rKLTeayaQDFg4NL3RK3Tnexsogb5LDyEPFEIII1qQf1NK+T/f4soDX+V8f1b1VPtOgInAHCFEEVpa7ky03HWk7+s9BOZ7XgKUSClX+14vQgv8gfxenwXslVJWSyldwP/Q3v9Af68P6Oy9Pa4YFyiB/ogPMA8Uvtz0S8B2KeVjbVYtBq70/f1K4IOT3bYTRUp5p5QyVUqZgfbefiWlvAz4Gvipb7OAumYAKWUFUCyEGOhbNB3YRgC/12gpm3FCiBDfv/UD1xzQ73Ubnb23i4ErfKNvxgHWNimeI5NSBsQPcA6wE9gD/Lmn23MCr3MS2te5zcBG3885aDnrL4FdwBdAdE+39QRd/1TgI9/f+wI/ALuBd4Dgnm7fCbjeEcBa3/v9PhAV6O81cB9QAGwF3gCCA/G9Bt5Cuw/hQvv2dk1n7y0g0EYW7gG2oI1K6vK5VAkERVGUABcoqRtFURSlEyrQK4qiBDgV6BVFUQKcCvSKoigBTgV6RVGUAKcCvaIoSoBTgV5RFCXA/T8E/6v67o0/hAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['training loss','training accuracy','validation loss','validation accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567e2e22",
      "metadata": {
        "id": "567e2e22"
      },
      "source": [
        "It should be noted here that the fit() function returns the loss function and metric values calculated for each epoch of the training process in the form of a tensor.\n",
        "\n",
        "We can use the trained model in practice in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2d97cb7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d97cb7a",
        "outputId": "689b1502-be60-4aa4-f6b1-aa2aad085980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 174ms/step\n",
            "0.3944836\n"
          ]
        }
      ],
      "source": [
        "# we use the trained model for classification of one vector (review)\n",
        "model=tf.keras.models.load_model('model_1.h5')\n",
        "print(model.predict(test_x[0:1])[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c99c964",
      "metadata": {
        "id": "9c99c964"
      },
      "source": [
        "We can evaluate the classification for the entire test set using the evaluate() function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7f8e9b5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8e9b5c",
        "outputId": "a25b8655-3784-4208-c22e-04c150d45f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 1s 3ms/step - loss: 0.5897 - accuracy: 0.6990\n",
            "Accuracy: 69.9 %\n"
          ]
        }
      ],
      "source": [
        "# we test our model for the whole test set\n",
        "model=tf.keras.models.load_model('model_1.h5')\n",
        "val=model.evaluate(test_x,test_y)\n",
        "print('Accuracy:',np.round(100*val[1],2),'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e9bf571",
      "metadata": {
        "id": "8e9bf571"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8cda891",
      "metadata": {},
      "source": [
        "Increasing the Number of Keywords:\n",
        "Observation: Increasing the number of keywords positively impacted the learning process, leading to a higher accuracy.\n",
        "Recommendation: This suggests that a more extensive vocabulary representation may capture more nuanced information from reviews.\n",
        "Changing the Way of Representation of Text Data:\n",
        "\n",
        "Observation: You didn't specify how you changed the representation, but it's essential to experiment with different text representation techniques.\n",
        "Recommendation: Try approaches like TF-IDF, word embeddings (e.g., Word2Vec, GloVe), or more advanced techniques like BERT embeddings.\n",
        "\n",
        "Increasing the Number of Hidden Layers:\n",
        "Observation: Increasing the number of hidden layers and neurons had a positive impact on both the learning process and the final results.\n",
        "Recommendation: This indicates that a more complex network architecture with more layers can capture more intricate patterns. Be cautious of overfitting, and consider regularization techniques.\n",
        "\n",
        "Modifying (Increasing, Decreasing) the Number of Neurons:\n",
        "Observation: Adjusting the number of neurons had an impact on the classification results.\n",
        "Recommendation: Experiment further with different neuron configurations to find the right balance between model complexity and generalization.\n",
        "\n",
        "Replacing Loss Function from Binary Crossentropy to MSE:\n",
        "Observation: Drastic changes did not significantly impact the effectiveness of the model.\n",
        "Recommendation: It's common for classification tasks to use binary crossentropy. MSE is often used in regression tasks. Stick to binary crossentropy for classification problems unless you have specific reasons to use MSE.\n",
        "\n",
        "Converting the ReLU Activation Function into Sigmoid:\n",
        "Observation: Changing activation functions had some impact on accuracy.\n",
        "Recommendation: Experimenting with different activation functions is a good practice. Sigmoid is commonly used in the output layer for binary classification, but ReLU is often used in hidden layers. Consider experimenting with both to find the optimal combination.\n",
        "\n",
        "Additional Recommendations:\n",
        "Learning Rate and Optimizer: Experiment with different learning rates and optimizers (e.g., Adam, SGD) to find the most effective combination for your task.\n",
        "Batch Size: Adjusting the batch size can also have an impact on the learning process. Experiment with different batch sizes to find the optimal one.\n",
        "Early Stopping: Implement early stopping to prevent overfitting and find the point where the model generalizes well.\n",
        "Regularization: Consider using dropout or other regularization techniques to prevent overfitting, especially with deeper architectures."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
